{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a34c8673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "import json\n",
    "import torch\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "#user defined modules\n",
    "import Face_exp_model  #face emotion recognition\n",
    "import speech_recognition_model #speech emotion recognition\n",
    "from model import NeuralNet\n",
    "from nltk_utils import tokenize,stem,bag_of_words #tokenize the sentence using nltk\n",
    "from model_training import model_training # chatbot model training\n",
    "print(\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62de780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "436a3e6a",
   "metadata": {},
   "source": [
    "### Face expression recogintion and Speech erm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "293e179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 157ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 152ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 112ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "face_output = Face_exp_model.Facerecognization()\n",
    "print(\"completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a69f43cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording\n",
      "Finished recording\n",
      "1/1 [==============================] - 0s 444ms/step\n"
     ]
    }
   ],
   "source": [
    "# Set up the speech recognition object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Set up the microphone stream\n",
    "mic = sr.Microphone()\n",
    "\n",
    "# Set up the text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "text = \"talk something to detect your emotion by speech\"\n",
    "    # Speak the response\n",
    "engine.say(text)\n",
    "engine.runAndWait()\n",
    "\n",
    "speech_recognition_model.recordAudio()\n",
    "speech_output = speech_recognition_model.Speechrecognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6233da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy\n",
      "disgust\n"
     ]
    }
   ],
   "source": [
    "print(face_output)\n",
    "print(speech_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4df9078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202 patterns\n",
      "28 tags: ['Amusement', 'Sarcasm', 'accomplishment', 'appreciating_the_present_moment', 'celebration', 'compliment', 'excitement', 'experiencing_new_things', 'funny', 'good_news', 'goodbye', 'gratitude', 'greeting', 'guitar', 'happy', 'helping', 'interests', 'job_success', 'neutral', 'neutral_smalltalk', 'new_experience', 'no_particular_events', 'relaxation', 'relaxing_or_taking_a_break', 'sad', 'sadness_General', 'sadness_Loss', 'thanks']\n",
      "268 unique stemmed words: [\"'m\", \"'re\", \"'s\", \"'ve\", ',', 'a', 'about', 'accomplish', 'adventur', 'all', 'am', 'amaz', 'an', 'and', 'ani', 'anxiou', 'anyth', 'appreci', 'are', 'assist', 'at', 'away', 'awesom', 'bad', 'balanc', 'be', 'beauti', 'been', 'befor', 'beginn', 'believ', 'best', 'better', 'boredom', 'brainstorm', 'break', 'burnt', 'bye', 'ca', 'can', 'care', 'celebr', 'comfort', 'compani', 'congratul', 'could', 'crack', 'day', 'depress', 'destress', 'did', 'die', 'do', 'done', 'down', 'downtim', 'dream', 'easi', 'easier', 'elat', 'end', 'enjoy', 'ever', 'everyth', 'exam', 'excit', 'exhaust', 'experi', 'experienc', 'explor', 'fail', 'fantast', 'feel', 'felt', 'food', 'for', 'found', 'from', 'fulfil', 'funni', 'get', 'go', 'goal', 'good', 'goodby', 'got', 'grate', 'great', 'greet', 'guess', 'guitar', 'hand', 'hang', 'happen', 'happi', 'hard', 'have', 'health', 'heard', 'hello', 'help', 'hey', 'hi', 'higher', 'hilari', 'hobbi', 'home', 'hopeless', 'how', 'huh', 'humor', 'hurt', 'i', 'idea', 'if', 'import', 'in', 'incred', 'instrument', 'interest', 'is', 'it', 'job', 'joke', 'joy', 'jump', 'just', 'keep', 'kind', 'know', 'later', 'laugh', 'learn', 'lend', 'let', 'letter', 'life', 'lifesav', 'like', 'littl', 'lol', 'lone', 'look', 'lost', 'lot', 'love', 'made', 'make', 'me', 'me-tim', 'meet', 'mental', 'met', 'mild', 'moment', 'move', 'much', 'my', \"n't\", 'need', 'never', 'new', 'news', 'next', 'nice', 'no', 'not', 'noth', 'of', 'off', 'offer', 'old', 'on', 'one', 'opinion', 'out', 'over', 'overjoy', 'overwhelm', 'owe', 'pain', 'paint', 'parti', 'peac', 'pet', 'place', 'plan', 'play', 'pleas', 'posit', 'present', 'prize', 'promot', 'reach', 'realli', 'receiv', 'recommend', 'relax', 'report', 'rofl', 'same', 'schedul', 'see', 'seen', 'sens', 'should', 'skill', 'so', 'some', 'someon', 'someth', 'start', 'stress', 'struggl', 'succeed', 'support', 'sure', 'sweet', 'take', 'talent', 'talk', 'target', 'tast', 'tell', 'thank', 'that', 'the', 'there', 'thi', 'thing', 'think', 'thrill', 'through', 'time', 'tip', 'to', 'today', 'too', 'tough', 'tri', 'until', 'unwind', 'up', 'vacat', 'view', 'visit', 'wa', 'wait', 'want', 'we', 'weather', 'week', 'welcom', 'went', 'what', 'where', 'with', 'without', 'wo', 'wonder', 'woohoo', 'work', 'would', 'yay', 'yoga', 'you', 'your', 'zone']\n",
      "268 28\n",
      "Epoch [100/1000], Loss: 0.1665\n",
      "Epoch [200/1000], Loss: 0.0039\n",
      "Epoch [300/1000], Loss: 0.0147\n",
      "Epoch [400/1000], Loss: 0.0003\n",
      "Epoch [500/1000], Loss: 0.0001\n",
      "Epoch [600/1000], Loss: 0.0001\n",
      "Epoch [700/1000], Loss: 0.0001\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.4433\n",
      "final loss: 0.4433\n",
      "training complete. file saved to data.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'training complete. file saved to data.pth'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728b6408",
   "metadata": {},
   "source": [
    "## chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2f32e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "with open('intents.json', 'r') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "    FILE = \"C:\\\\Users\\\\gana4\\\\MAJOR PROJECT\\\\data.pth\"\n",
    "    data = torch.load(FILE)\n",
    "\n",
    "    input_size = data[\"input_size\"]\n",
    "    hidden_size = data[\"hidden_size\"]\n",
    "    output_size = data[\"output_size\"]\n",
    "    all_words = data['all_words']\n",
    "    tags = data['tags']\n",
    "    model_state = data[\"model_state\"]\n",
    "\n",
    "    model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "    model.load_state_dict(model_state)\n",
    "    model.eval()\n",
    "\n",
    "    bot_name = \"chatbot\"\n",
    "x = face_output\n",
    "y = speech_output\n",
    "def combination_emotion():\n",
    "    \n",
    "    if (x == \"happy\" or x == \"neutral\" or x == \"surprise\") and (y == \"neutral\" or y == \"calm\" or y == \"happy\" or y == \"surprised\"):\n",
    "        emotion = 'happy'\n",
    "        return emotion\n",
    "    elif (x == \"happy\" or x == \"neutral\" or x == \"surprised\") and (y == \"sad\" or y == \"angry\" or y == \"fearful\" or y == \"disgust\"):\n",
    "        emotion = \"neutral\"\n",
    "        return emotion\n",
    "    elif (x == \"angry\" or x == \"fear\" or x == \"sad\") and (y == \"neutral\" or y == \"calm\" or y == \"happy\" or y == \"surprised\"):\n",
    "        emotion = \"neutral\"\n",
    "        return emotion\n",
    "    elif (x == \"angry\" or x == \"fear\" or x == \"sad\") and (y == \"sad\" or y == \"angry\" or y == \"fearful\" or y == \"disgust\"):\n",
    "        emotion = \"sad\"\n",
    "        return emotion\n",
    "    # print(\"Let's chat! (type 'quit' to exit)\")\n",
    "def chatbot():\n",
    "    #initiative\n",
    "    x = \"How can i call you?\"\n",
    "\n",
    "    with mic as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        print(\"chatbot :\"+x)\n",
    "        def handle_input(audio):\n",
    "            try:\n",
    "                u_name = r.recognize_google(audio)\n",
    "                print(\"you: \"+u_name)\n",
    "                if 'is' in u_name: \n",
    "                    u_name = u_name.split(\"is\")[-1].strip()\n",
    "                    user_name = u_name\n",
    "                elif 'am' in u_name:\n",
    "                    u_name = u_name.split(\"am\")[-1].strip()\n",
    "                    user_name = u_name\n",
    "                elif 'me' in u_name:\n",
    "                    u_name = u_name.split(\"me\")[-1].strip()\n",
    "                    user_name = u_name\n",
    "                elif 'as' in u_name:\n",
    "                    u_name = u_name.split(\"as\")[-1].strip()\n",
    "                    user_name = u_name\n",
    "                else:\n",
    "                    user_name =  u_name\n",
    "\n",
    "                emotion = combination_emotion()\n",
    "                if emotion == \"happy\":\n",
    "                    text2 = f\"chatbot: {user_name}, I'm glad to hear that! Tell me more about why you're feeling happy.\"\n",
    "                elif emotion == \"sad\":\n",
    "                    text2 = f\"chatbot: {user_name}, I'm sorry to hear that. Would you like to talk more about what's been making you feel sad?\"\n",
    "                elif emotion == \"angry\":\n",
    "                    text2 = f\"chatbot: {user_name}, I can understand why you might be feeling angry. Would you like to talk about what's been frustrating you?\"\n",
    "                elif emotion == \"fearful\":\n",
    "                    text2 = f\"chatbot: {user_name}, I'm sorry to hear that you're feeling scared. Would you like to talk more about what's been worrying you?\"\n",
    "                else:\n",
    "                    text2  = f\"chatbot: {user_name}, It sounds like you're feeling neutral about things. Is there anything in particular that's been on your mind?\"\n",
    "                print(text2)    \n",
    "            except sr.UnknownValueError:\n",
    "                respond('Sorry, I could not understand what you said')\n",
    "            except sr.RequestError as e:\n",
    "                respond('Sorry, there was an error processing your request')\n",
    "                \n",
    "        while True:\n",
    "            try:\n",
    "                print(\"listening...\")\n",
    "                audio = r.listen(source, timeout=6.0)\n",
    "                handle_input(audio)\n",
    "                break\n",
    "            except sr.WaitTimeoutError:\n",
    "                print('No input detected for 6 seconds, ending session')\n",
    "                respond('Goodbye')\n",
    "                break\n",
    "            except sr.UnknownValueError:\n",
    "                respond('Sorry, I could not understand what you said')\n",
    "                break\n",
    "            except sr.RequestError as e:\n",
    "                respond('Sorry, there was an error processing your request')\n",
    "                break\n",
    "\n",
    "        \n",
    "\n",
    "def responses():\n",
    "    while True:\n",
    "        def respond(sentence):\n",
    "            sentence = tokenize(sentence)\n",
    "            X = bag_of_words(sentence, all_words)\n",
    "            X = X.reshape(1, X.shape[0])\n",
    "            X = torch.from_numpy(X).to(device)\n",
    "\n",
    "            output = model(X)\n",
    "            _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "            tag = tags[predicted.item()]\n",
    "\n",
    "            probs = torch.softmax(output, dim=1)\n",
    "            prob = probs[0][predicted.item()]\n",
    "            if prob.item() > 0.75:\n",
    "                for intent in intents['intents']:\n",
    "                    if tag == intent[\"tag\"]:\n",
    "                        bot_chat = random.choice(intent['responses'])\n",
    "                        print(f\"{bot_name}: {bot_chat}\")\n",
    "            else:\n",
    "                print(f\"{bot_name}: I do not understand...\")\n",
    "\n",
    "        # Define a function to handle user input\n",
    "        def handle_input(audio):\n",
    "            try:\n",
    "                sentence = r.recognize_google(audio)\n",
    "                print(f\"You: {sentence}\")\n",
    "                if sentence == \"exit\":\n",
    "                    sys.exit()\n",
    "                else:\n",
    "                    respond(sentence)\n",
    "                \n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Sorry, I could not understand what you said repeat again\")\n",
    "                engine.say('Sorry, I could not understand what you said, repeat again')\n",
    "                engine.runAndWait()\n",
    "            except sr.RequestError as e:\n",
    "                engine.say('Sorry, there was an error processing your request')\n",
    "                engine.runAndWait()\n",
    "            \n",
    "\n",
    "        # Start the microphone stream\n",
    "        with mic as source:\n",
    "            r.adjust_for_ambient_noise(source)\n",
    "            while True:\n",
    "                try:\n",
    "                    print(\"listening...\")\n",
    "                    audio = r.listen(source,timeout = 6.0)\n",
    "                    handle_input(audio)\n",
    "                except sr.WaitTimeoutError:\n",
    "                    print('Sorry, I it is timed out')\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f2fd09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80993be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chatbot :How can i call you?\n",
      "listening...\n",
      "you: call me as Durga\n",
      "chatbot: as Durga, It sounds like you're feeling neutral about things. Is there anything in particular that's been on your mind?\n",
      "listening...\n",
      "You: no nothing tell me a joke\n",
      "chatbot: Until next time, stay well\n",
      "listening...\n",
      "Sorry, I could not understand what you said repeat again\n",
      "listening...\n",
      "You: tell me a joke hello\n",
      "chatbot: What did the buffalo say when his son left for college? Bison.\n",
      "listening...\n",
      "You: spectrum 8257 DMA diagram\n",
      "chatbot: I do not understand...\n",
      "listening...\n"
     ]
    }
   ],
   "source": [
    "chatbot()\n",
    "responses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbe1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
